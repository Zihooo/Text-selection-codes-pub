{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ZVjSGx2hzd"
      },
      "source": [
        "# The Feature Extraction Approach for Personality Score Prediction\n",
        "This colab is written in **Python** to illistrate the process of *feature extraction approach* with TF-IDF scores and a random forest classifier when predicting personality scores from texts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gsl9k5J_zEX"
      },
      "source": [
        "### **Step 1 Text Preprocessing**\n",
        "In the text preprocessing phase, we 1. Removed the special characters. 2. Tokenized the texts. 3. Lowercased all texts. 4. Removed stop words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfgWVbpqSmmM",
        "outputId": "b8515e66-21c7-4406-935a-80458fd0823b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google drive to get access to the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "QlXg7JiwR9nN",
        "outputId": "d749758c-17b0-43af-bea1-5818c83a5a4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import required pacakges\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDqn_eTySOiG"
      },
      "outputs": [],
      "source": [
        "# import raw data\n",
        "csv_file = '/content/drive/MyDrive/Text Selection Paper Codes/data/all_text_latent_extract_10.csv' # path to data file\n",
        "df = pd.read_csv(csv_file, encoding= 'unicode_escape')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGovw9XbaKxQ"
      },
      "outputs": [],
      "source": [
        "#defining the function to remove special characters and punctuations\n",
        "def remove_punctuation(text):\n",
        "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
        "    return punctuationfree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbGrQYASbCdp"
      },
      "outputs": [],
      "source": [
        "#storing the and punctuations free text\n",
        "df['clean_text']= df['All_response'].apply(lambda x:remove_punctuation(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y-UyeBhYq1G"
      },
      "outputs": [],
      "source": [
        "# lowercase the texts\n",
        "df['msg_lower']= df['clean_text'].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmp2UsvZbmgD"
      },
      "outputs": [],
      "source": [
        "#applying function to the column\n",
        "df['msg_tokenied']= df['msg_lower'].apply(word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UDYbRjQWnit"
      },
      "outputs": [],
      "source": [
        "# Load the pre-defined stop words dictionary\n",
        "stop_words = stopwords.words('english')\n",
        "# Extend the stop words distionary with some high frequency words in the current data\n",
        "stop_words.extend([\"would\",\"dont\",\"could\",\"id\",\"X\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kpw6UJ13c3KR"
      },
      "outputs": [],
      "source": [
        "# define remove stop words function\n",
        "def remove_english_stopwords_func(text):\n",
        "    # check in lowercase\n",
        "    t = [token for token in text if token.lower() not in stop_words]\n",
        "    text = ' '.join(t)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUz1bSpXWT74"
      },
      "outputs": [],
      "source": [
        "# remove stop words\n",
        "df['No_Stop_Words'] = df['msg_tokenied'].apply(remove_english_stopwords_func)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5JOQ3mqV0fQ"
      },
      "source": [
        "### **Step 2 feature extraction**\n",
        "In the feature extraction phase, we generate the TF-IDF vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhTnhBnNir7v"
      },
      "outputs": [],
      "source": [
        "document = df.No_Stop_Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saHOZdwWShux"
      },
      "outputs": [],
      "source": [
        "# generate TF-IDF vectors with 5000 features\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "vectors = vectorizer.fit_transform(document)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "dense = vectors.todense()\n",
        "denselist = dense.tolist()\n",
        "tfidf = pd.DataFrame(denselist, columns=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GURFo0Eu4DzC"
      },
      "outputs": [],
      "source": [
        "# add labels to TF-IDF vectors\n",
        "tfidf['ascore'] = df['ascore']\n",
        "tfidf['cscore'] = df['cscore']\n",
        "tfidf['nscore'] = df['nscore']\n",
        "tfidf['escore'] = df['escore']\n",
        "tfidf['oscore'] = df['oscore']\n",
        "tfidf['lead_task'] = df['task']\n",
        "tfidf['lead_people'] = df['people']\n",
        "tfidf['lead_char'] = df['char']\n",
        "tfidf['lead_ethic'] = df['ethic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGduVocxlzCc"
      },
      "outputs": [],
      "source": [
        "# save the TF-IDF scores\n",
        "tfidf.to_csv('/content/drive/MyDrive/Text Selection Paper Codes/data/tfidf_2000.csv')  # after the file has been saved, it was further splited into a training, evaluation and a testing set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE7I4LV456f2"
      },
      "source": [
        "### **Step 3 Score Prediction**\n",
        "In the score prediction phase, we used a random forest model to predict personality scores based on TF-IDF vectors. We used the prediction  of Extraversion scores as an example in the current code sample. Other predictions can be achieved by changing the label column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Biotx2_j8Zsl"
      },
      "outputs": [],
      "source": [
        "# import required pacakges\n",
        "from scipy.stats import pearsonr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import RandomizedSearchCV, KFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCLYGgt1kUKy"
      },
      "outputs": [],
      "source": [
        "# specifiy the first 2000 columns as features, and the personality scores as labels\n",
        "#train_features = train_set.iloc[:,0:2000]\n",
        "#test_features = test_set.iloc[:,0:2000]\n",
        "#train_labels = train_set.escore\n",
        "#test_labels = test_set.escore\n",
        "#feature_list = list(train_features.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laLnghExoeLx"
      },
      "outputs": [],
      "source": [
        "tfidf_set = pd.read_csv('/content/drive/MyDrive/Text Selection Paper Codes/data/tfidf_5000.csv', encoding= 'unicode_escape')\n",
        "# specifiy the first 2000 columns as features, and the personality scores as labels\n",
        "X = tfidf_set.iloc[:,0:5000]\n",
        "y = tfidf_set.oscore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Srz59PCfn4Lv"
      },
      "outputs": [],
      "source": [
        "# Number of folds\n",
        "num_folds = 5\n",
        "\n",
        "# Initialize KFold for the outer loop (train-test split)\n",
        "kf_outer = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Parameter grid for RandomForestClassifier\n",
        "param_grid = {\n",
        "    'n_estimators': [200, 500, 800],\n",
        "    'max_depth': [20, 50, 100],\n",
        "    # Add other hyperparameters you want to tune\n",
        "}\n",
        "all_fold_scores = []\n",
        "# Outer loop for train-test split\n",
        "for fold_index, (train_index, test_index) in enumerate(kf_outer.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    task = tfidf_set.lead_task.iloc[test_index]\n",
        "    people = tfidf_set.lead_people.iloc[test_index]\n",
        "    char = tfidf_set.lead_char.iloc[test_index]\n",
        "    ethic = tfidf_set.lead_ethic.iloc[test_index]\n",
        "\n",
        "    # Initialize KFold for the inner loop (cross-validation within the training data)\n",
        "    kf_inner = KFold(n_splits=4, shuffle=True, random_state=42)\n",
        "\n",
        "    # Initialize RandomForestClassifier\n",
        "    rf_regressor = RandomForestRegressor()\n",
        "\n",
        "    # Define Pearson correlation as a custom scorer\n",
        "    pearson_scorer = make_scorer(lambda y_true, y_pred: np.corrcoef(y_true, y_pred)[0, 1], greater_is_better=True)\n",
        "\n",
        "    # Initialize GridSearchCV with RandomForestClassifier and the parameter grid\n",
        "    grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=kf_inner, scoring=pearson_scorer)\n",
        "\n",
        "    # Fit the model on the training data with grid search for hyperparameter tuning\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best hyperparameters found by GridSearchCV\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    # Train the model with the best hyperparameters on the entire training set\n",
        "    rf_regressor.set_params(**best_params)\n",
        "\n",
        "    rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    y_pred = rf_regressor.predict(X_test)\n",
        "\n",
        "    # save the predicted output\n",
        "    result_df = pd.DataFrame({\n",
        "      'fold_index': fold_index,\n",
        "      'test_index': test_index,\n",
        "      'y_pred': y_pred,\n",
        "      'y_label': y_test\n",
        "    })\n",
        "    # Save the DataFrame to a CSV file\n",
        "    fold_results = pd.DataFrame({'fold_index': fold_index, 'test_index': test_index, 'predicted_scores': y_pred})\n",
        "\n",
        "    # Append the DataFrame to the list\n",
        "    all_fold_scores.append(fold_results)\n",
        "\n",
        "    # Calculate Pearson correlation on the test set (convergent validity)\n",
        "    correlation, _ = pearsonr(y_pred, y_test)\n",
        "\n",
        "    # calculate criterion validity\n",
        "    criterion_task = np.corrcoef(y_pred,task)[0, 1]\n",
        "    criterion_people = np.corrcoef(y_pred,people)[0, 1]\n",
        "    criterion_char = np.corrcoef(y_pred,char)[0, 1]\n",
        "    criterion_ethic = np.corrcoef(y_pred,ethic)[0, 1]\n",
        "\n",
        "    # incremental validity\n",
        "    #regression1 = LinearRegression()\n",
        "    #regression1.fit(y_test, task)\n",
        "\n",
        "\n",
        "    print(f\"best parameters are:{best_params}\")\n",
        "    print(f\"Pearson Correlation on Test Set: {correlation}\")\n",
        "    print(f\"Criterion Correlation on task: {criterion_task}\")\n",
        "    print(f\"Criterion Correlation on people: {criterion_people}\")\n",
        "    print(f\"Criterion Correlation on char: {criterion_char}\")\n",
        "    print(f\"Criterion Correlation on ethic: {criterion_ethic}\")\n",
        "    print(\"-\" * 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzev0dQnb-xU"
      },
      "outputs": [],
      "source": [
        "all_results = pd.concat(all_fold_scores, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eAnCbQocQ8D"
      },
      "outputs": [],
      "source": [
        "all_results.to_csv('/content/drive/MyDrive/Text Selection Paper Codes/final saved outputs/TFIDF/Oscore.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}