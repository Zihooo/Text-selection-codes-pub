{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zihooo/Text-selection-codes-pub/blob/main/New_Prediction_Model_(DeBERTa).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ZVjSGx2hzd"
      },
      "source": [
        "# Transformer Models for Personality Score Prediction\n",
        "This colab is written in **Python** to illistrate the process of *fine-tuning*  state-of-the-art **Transformer** models to predict personality scores. In this code sample, we used **Deberta-based** as an example of a transformer and **Extraversion** as a sample personality trait. We've made notes in the code about the changes you'd need to make to use other transformers or predict other personality traits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIae_k5emARe",
        "outputId": "bbe840d5-22d6-4116-acc2-86cf449d6447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google drive to get access to the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7S6aRPS_w63"
      },
      "outputs": [],
      "source": [
        "## install required pacakges\n",
        "! pip install transformers==4.28.0\n",
        "! pip install sentencepiece\n",
        "! pip install datasets\n",
        "! pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A25eSs8QUkS8"
      },
      "outputs": [],
      "source": [
        "# import pacakges\n",
        "from transformers import AutoConfig, AutoTokenizer, TrainingArguments, Trainer, EarlyStoppingCallback, IntervalStrategy\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import scipy\n",
        "from scipy.stats import pearsonr\n",
        "from scipy.special import softmax\n",
        "import statistics\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from warnings import warn\n",
        "import os\n",
        "import sys\n",
        "import gc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0eCZR2ngddV"
      },
      "source": [
        "### Using a GPU\n",
        "To speed things up you can use a *GPU* (*optional*).\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, confirm that you can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXnDmXR7RDr2"
      },
      "outputs": [],
      "source": [
        "# A helper function to check for a GPU\n",
        "def get_gpu ():\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return torch.cuda.current_device()\n",
        "  else:\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXevB2XPpocQ",
        "outputId": "9d7898f3-0670-424d-e0a0-70791984ea98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "get_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE95PDPffa4-",
        "outputId": "8fb8b1e4-fbff-4c78-efcd-f6b37b578a0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Feb  3 17:21:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8              11W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkXTg-LmUAkH"
      },
      "source": [
        "### Functions and Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p21aZOBc9Pvh"
      },
      "outputs": [],
      "source": [
        "#@title Load user-defined utility functions\n",
        "# Import Data function\n",
        "def import_data(path, text_col, label_col, index_col = None, index_val = None, enc = 'latin1'):\n",
        "  \"\"\"Import a CSV of sentences\n",
        "\n",
        "  Args:\n",
        "    path: A csv file path\n",
        "    text_col: Name of column in csv containing sentences\n",
        "    label_col: Name of column containing labels\n",
        "    enc: File encoding to be used (optional)\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(path, encoding = enc,keep_default_na=False)\n",
        "  if not isinstance(index_val, type(None)):\n",
        "    df = df[df[index_col] == index_val]\n",
        "  if label_col is None:\n",
        "    return df[text_col].tolist(), df\n",
        "  return df[text_col].tolist(), df[label_col].tolist(), df\n",
        "\n",
        "\n",
        "# Get model for simple transformers\n",
        "def get_model(model_type):\n",
        "    if  model_type == \"specter\":\n",
        "        model_name = \"allenai/specter\"\n",
        "    elif model_type == \"bert\":\n",
        "        model_name = \"bert-base-cased\"\n",
        "    elif model_type == \"roberta\":\n",
        "        model_name = \"roberta-large\"\n",
        "    elif model_type == \"distilbert\":\n",
        "        model_name = \"distilbert-base-cased-distilled-squad\"\n",
        "    elif model_type == \"distilroberta\":\n",
        "        model_type = \"roberta\"\n",
        "        model_name = \"cross-encoder/stsb-distilroberta-base\"\n",
        "    elif model_type == \"electra-base\":\n",
        "        model_type = \"electra\"\n",
        "        model_name = \"cross-encoder/ms-marco-electra-base\"\n",
        "    elif model_type == \"xlnet\":\n",
        "        model_name = \"xlnet-large-cased\"\n",
        "    elif model_type == \"bart\":\n",
        "        model_name = \"facebook/bart-large\"\n",
        "    elif model_type == \"deberta\":\n",
        "        model_type = \"debertav2\"\n",
        "        model_name = \"microsoft/deberta-v3-large\"\n",
        "    elif model_type == \"albert\":\n",
        "        model_name = \"albert-xlarge-v2\"\n",
        "    elif model_type == \"xlmroberta\":\n",
        "        model_name = \"xlm-roberta-large\"\n",
        "    else:\n",
        "        warnings.warn(\"model_type not a pre-defined, setting model_type to model_name\")\n",
        "        model_name = model_type\n",
        "    return model_type, model_name\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnZLUABzOfmc"
      },
      "outputs": [],
      "source": [
        "# eval metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_selection import r_regression\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def compute_metrics_for_regression(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    labels = labels.reshape(-1, 1)\n",
        "    mse = mean_squared_error(labels, logits)\n",
        "    r = pearsonr(labels.reshape(-1), logits.reshape(-1))\n",
        "    rscore = r[0].tolist()\n",
        "    single_squared_errors = ((logits - labels).flatten()**2).tolist()\n",
        "    return {\"mse\": mse, \"r\": rscore}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M85LHN2IhlcH"
      },
      "outputs": [],
      "source": [
        "#@title Data Class\n",
        "class TextClassificationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdULdNEfUYb1"
      },
      "source": [
        "### Defining Variables\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We define our variables for purposes described in our research manuscripte. However, we encourage researchers and practitioners to try out alternative models. In addition, we wanted to minimize the tuning hyper-parameters during training as the aim of this research is to highlight Transformers in a baseline sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8tlBiCW5mBy"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BASE_MODEL = 'microsoft/deberta-v3-base' # replace with \"allenai/longformer-base-4096\" for longformer\n",
        "LEARNING_RATE = 1e-5\n",
        "MAX_LENGTH = 512      # can be increased to 4096 when use longformer, a longer sequence leads to heavier computation load\n",
        "BATCH_SIZE = 12       # batch size is defined based on available computational resource (GPU memory)\n",
        "EPOCHS = 10           # may increase this number if there is no diminishing return on evaluation metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU5mojBFURyy"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Fine-tuning A Transformer Model\n",
        "\n",
        "\n",
        "---\n",
        "This example demonstrates the fine-tuning process for the pupose of score prediction from text data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoOpPwcYvTvc"
      },
      "source": [
        "### Importing and formatting Training Data\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Since we have already mount this notebood at our drive, we can directly import data from Google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf59m2OcXIIA"
      },
      "outputs": [],
      "source": [
        "# read the whole dataset (selected text)\n",
        "all_text, all_labels, all_raw_data = import_data(\"/content/drive/MyDrive/Text Selection Paper Codes/data/all_text_latent_extract_10.csv\", \"texte\", \"escore\")\n",
        "\n",
        "\n",
        "# add tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Jx-TAHYaoSR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, KFold, train_test_split\n",
        "\n",
        "all_pred_scores = []\n",
        "\n",
        "num_folds = 5\n",
        "kf_outer = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "for fold_index, (train_index, test_index) in enumerate(kf_outer.split(all_raw_data)):\n",
        "    X_train, X_test = [all_text[i] for i in train_index], [all_text[i] for i in test_index]\n",
        "    y_train, y_test = [all_labels[i] for i in train_index], [all_labels[i] for i in test_index]\n",
        "\n",
        "    #creating evaluation set\n",
        "    train_text, eval_text = train_test_split(X_train, test_size=0.25, random_state=42)\n",
        "    train_labels, eval_labels = train_test_split(y_train, test_size=0.25, random_state=42)\n",
        "    #tokenizing the data\n",
        "    #train_labels_indx, lab_to_id, num_labs = map_labels_to_keys(train_labels)\n",
        "    train_encodings = tokenizer(train_text, truncation=True, max_length = MAX_LENGTH,padding='max_length')\n",
        "    train_dataset = TextClassificationDataset(train_encodings, train_labels)\n",
        "\n",
        "    #eval_labels_indx, _, _ = map_labels_to_keys(eval_labels)\n",
        "    eval_encodings = tokenizer(eval_text, truncation=True, max_length = MAX_LENGTH,padding='max_length')\n",
        "    eval_dataset = TextClassificationDataset(eval_encodings, eval_labels)\n",
        "\n",
        "    #test_labels_indx, _, _ = map_labels_to_keys(test_labels)\n",
        "    test_encodings = tokenizer(X_test, truncation=True, max_length = MAX_LENGTH,padding='max_length')\n",
        "    test_dataset = TextClassificationDataset(test_encodings, y_test)\n",
        "\n",
        "    # load the model\n",
        "    MODEL = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=1, force_download = True)\n",
        "\n",
        "    # arguments\n",
        "    training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Text Selection Paper Codes/checkpoints/deberta\", # directory to save the model\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    seed = 100,                                                    # though the seed number for training is fixed here, there is still some randomness in model innitiations.\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    evaluation_strategy=IntervalStrategy.STEPS,\n",
        "    eval_steps = 22,\n",
        "    save_steps = 440,\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps = 22,\n",
        "    metric_for_best_model=\"r\", greater_is_better = True,    # This metric can also be mse, and change greater is better to False.\n",
        "                                                           # No matter which to use, an observation on the training log is necessary for model selection.\n",
        "    load_best_model_at_end=True,     # this will save the epoch with the lowest loss metric as final output.\n",
        "    weight_decay=0.01)\n",
        "\n",
        "    # initialize trainer\n",
        "    trainer = Trainer(model=MODEL,\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = eval_dataset,\n",
        "    compute_metrics = compute_metrics_for_regression,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)])\n",
        "\n",
        "    #training\n",
        "    trainer.train()\n",
        "\n",
        "    #evaluation\n",
        "    trainer.eval_dataset=eval_dataset\n",
        "    print(trainer.evaluate())\n",
        "\n",
        "    #prediction\n",
        "    # run prediction\n",
        "    pred_set = trainer.predict(test_dataset)\n",
        "    # save the predicted results into a list\n",
        "    xss = pred_set[0]\n",
        "    #flat_list = [x for xs in xss for x in xs]\n",
        "\n",
        "    #convergent validity\n",
        "    correlation = pearsonr(xss,pred_set[1])\n",
        "\n",
        "    # calculate criterion validity\n",
        "    task = all_raw_data.task.iloc[test_index]\n",
        "    people = all_raw_data.people.iloc[test_index]\n",
        "    char = all_raw_data.char.iloc[test_index]\n",
        "    ethic = all_raw_data.ethic.iloc[test_index]\n",
        "\n",
        "\n",
        "    criterion_task = np.corrcoef(xss,task)[0, 1]\n",
        "    criterion_people = np.corrcoef(xss,people)[0, 1]\n",
        "    criterion_char = np.corrcoef(xss,char)[0, 1]\n",
        "    criterion_ethic = np.corrcoef(xss,ethic)[0, 1]\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    fold_results = pd.DataFrame({'fold_index': fold_index, 'test_index': test_index, 'predicted_scores': xss})\n",
        "\n",
        "    # Append the DataFrame to the list\n",
        "    all_pred_scores.append(fold_results)\n",
        "\n",
        "    # calculate the correlation between predicted scores and labels\n",
        "    print(f\"Pearson Correlation on Test Set: {correlation}\")\n",
        "    print(f\"Criterion Correlation on task: {criterion_task}\")\n",
        "    print(f\"Criterion Correlation on people: {criterion_people}\")\n",
        "    print(f\"Criterion Correlation on char: {criterion_char}\")\n",
        "    print(f\"Criterion Correlation on ethic: {criterion_ethic}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BZVTyj6mnGl"
      },
      "outputs": [],
      "source": [
        "save_pred_scores = pd.concat(all_pred_scores, ignore_index=True)\n",
        "save_pred_scores.to_csv('/content/drive/MyDrive/Text Selection Paper Codes/final saved outputs/selection/Oscore2.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}