{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zihooo/Text-selection-codes-pub/blob/main/Classification_Model_for_Text_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ZVjSGx2hzd"
      },
      "source": [
        "# Fine-tuning Transformer Models for Text Classification\n",
        "This colab is written in **Python** to illistrate the process of *fine-tuning*  state-of-the-art **Transformer** models to classify personality items. In this context the fine-tuning process involves training models with a relatively small amount of items with known trait labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAXM9DDgrzuE"
      },
      "outputs": [],
      "source": [
        "# Mount Google drive to get access to the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7S6aRPS_w63"
      },
      "outputs": [],
      "source": [
        "## install required pacakges\n",
        "! pip install transformers==4.28.0\n",
        "! pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A25eSs8QUkS8"
      },
      "outputs": [],
      "source": [
        "# import pacakges\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive # optional for getting data\n",
        "from typing import Dict, List # for type hinting\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import gc\n",
        "import warnings\n",
        "import requests\n",
        "from io import StringIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0eCZR2ngddV"
      },
      "source": [
        "### Using a GPU\n",
        "To speed things up you can use a *GPU* (*optional*).\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, confirm that you can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXnDmXR7RDr2"
      },
      "outputs": [],
      "source": [
        "# A helper function to check for a GPU\n",
        "# To check if you are able to use a GPU environment in Colab click the `Runtime` menu above, then select `Change Runtime Type`, the pick \"GPU\" for the `Hardware Accelerator` dropdown\n",
        "def get_gpu ():\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return torch.cuda.current_device()\n",
        "  else:\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE95PDPffa4-"
      },
      "outputs": [],
      "source": [
        "get_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkXTg-LmUAkH"
      },
      "source": [
        "### Functions and Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyQQt1yuCi2b"
      },
      "outputs": [],
      "source": [
        "#@title Data Class\n",
        "class TextClassificationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ekBE-p49KLC"
      },
      "outputs": [],
      "source": [
        "#@title Fine-tuning function\n",
        "def fine_tune(model, text, labels, train_args, multi_label: bool = False,\n",
        "              time_stamp_out_dir: bool = True, max_seq_len: str = 'longest'):\n",
        "  \"\"\"Fine-tune a Transformers model for text classification\n",
        "  \n",
        "  Args:\n",
        "    model: a valid string representing the model_type\n",
        "    text: a list of sentences to use for fine-tuning\n",
        "    labels: a list of labels\n",
        "    train_args: dictionary of training arguments\n",
        "    multi_label: A boolean (True/False). If True (False by default) will perform multi-label classification \n",
        "    time_stamp_out_dir: Perform multi-label classification (optional)\n",
        "    max_seq_len: string determining how to pad text sequences (optional)\n",
        "  \"\"\"\n",
        "  if time_stamp_out_dir:\n",
        "    _, new_out_dir = update_directories(train_args.output_dir)\n",
        "    train_args.output_dir = new_out_dir\n",
        "\n",
        "  _, model_name = get_model(model)\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "  train_labels_indx, lab_to_id, num_labs = map_labels_to_keys(labels)\n",
        "  \n",
        "  if max_seq_len == 'longest':\n",
        "    train_encodings = tokenizer(text, truncation=True, padding=True)\n",
        "  else:\n",
        "    train_encodings = tokenizer(text, padding='max_len', max_length=max_seq_len)\n",
        "\n",
        "  train_dataset = TextClassificationDataset(train_encodings, train_labels_indx)\n",
        "    \n",
        "  model = AutoModelForSequenceClassification.from_pretrained(\n",
        "      model_name, num_labels=num_labs, label2id = lab_to_id\n",
        "      )\n",
        "  \n",
        "  if multi_label:\n",
        "    model.problem_type = \"multi_label_classification\"\n",
        "\n",
        "  trainer = Trainer(model=model,\n",
        "      args = training_args,\n",
        "      train_dataset = train_dataset\n",
        "    )\n",
        " \n",
        "  trainer.train()\n",
        "    \n",
        "  return trainer, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p21aZOBc9Pvh"
      },
      "outputs": [],
      "source": [
        "#@title Load user-defined utility functions\n",
        "\n",
        "# Import Data function\n",
        "def import_data(path: str, text_col, label_col = None, enc = 'latin1'):\n",
        "  \"\"\"Import a CSV of sentences\n",
        "  \n",
        "  Args:\n",
        "    path: A csv file path or url pointing at CSV file\n",
        "    text_col: Name of column in csv containing sentences\n",
        "    label_col: Name of column containing labels\n",
        "    enc: File encoding to be used (optional)\n",
        "  \"\"\"\n",
        "  if (path.startswith(\"http\")):\n",
        "      res = requests.get(path,\n",
        "                         headers= {'User-Agent': 'Mozilla/5.0',\n",
        "                                   \"X-Requested-With\": \"XMLHttpRequest\"})\n",
        "      path = StringIO(res.text)\n",
        "  df = pd.read_csv(path, encoding = enc)\n",
        "  \n",
        "  if label_col is None:\n",
        "    return df[text_col].tolist(), df\n",
        "  return df[text_col].tolist(), df[label_col].tolist(), df\n",
        "\n",
        "# Map labels to keys\n",
        "def map_labels_to_keys(labels: str, sort_labels = True):\n",
        "  \"\"\"Map text labels to integers\n",
        "  \n",
        "  Args:\n",
        "    labels: a list/vector of text labels\n",
        "    sort_labels: Sort labels alphabetically before recoding (optional)\n",
        "  \"\"\"\n",
        "  k = list(dict.fromkeys(labels))\n",
        "  if sort_labels:\n",
        "    k.sort()\n",
        "  labels_to_id = {k[i] : int(i) for i in range(0, len(k))}\n",
        "  labels_out = []\n",
        "  for j in labels:\n",
        "    labels_out.append(labels_to_id[j])\n",
        "  return labels_out, labels_to_id, len(k)\n",
        "\n",
        "# Update model directories\n",
        "def update_directories(model_output_dir: str) -> str:\n",
        "    file_time = datetime.datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
        "    model_output_dir = f'{model_output_dir}-{file_time}/'\n",
        "    out_file = f\"{model_output_dir}/{file_time}_results.csv\"\n",
        "    return out_file, model_output_dir\n",
        "\n",
        "# Get model for simple transformers\n",
        "def get_model(model_type: str) -> List[str]:\n",
        "    model_dict = {\n",
        "        'albert': \"albert-xlarge-v2\",\n",
        "        'bart': \"facebook/bart-large\",\n",
        "        'bert': \"bert-base-cased\",\n",
        "        'deberta': [\"debertav2\", \"microsoft/deberta-v3-large\"],\n",
        "        'distilbert': \"distilbert-base-cased-distilled-squad\",\n",
        "        'distilroberta': ['roberta', \"cross-encoder/stsb-distilroberta-base\"],\n",
        "        'electra': \"cross-encoder/ms-marco-electra-base\",\n",
        "        'roberta': \"roberta-large\",\n",
        "        'xlnet': \"xlnet-large-cased\",\n",
        "        'xmlroberta': \"xlm-roberta-large\",\n",
        "    }\n",
        "    model_name = model_dict.get(model_type, [model_type, model_type])\n",
        "    if isinstance(model_name, str):\n",
        "        model_name = [model_type, model_name]\n",
        "    return model_name\n",
        "\n",
        "# Format output data function\n",
        "def format_output_data(raw_outputs, test_case_ids = None, label_values = None, output_probabilities: bool = True,\n",
        "                       output_predicted_label: bool = True):\n",
        "  \"\"\"Format test data to be output to CSV\n",
        "  \n",
        "  Args:\n",
        "    raw_outputs: The raw_outputs from transformers model.predict()\n",
        "    test_case_ids: A list of test case ids (optional)\n",
        "    label_values: A list of *unique ordered* labels (optional)\n",
        "    output_probabilities: A boolean (True/False). If True (the default) will convert logit predictions to probabilities\n",
        "    output_predicted_label: A boolean (True/False). If True (the default) will append a 'predicted' column as most likely label  \n",
        "  \"\"\"\n",
        "  \n",
        "  out_df = pd.DataFrame(raw_outputs)\n",
        "\n",
        "  if output_probabilities:\n",
        "      out_df = softmax(out_df, axis=1)\n",
        "  \n",
        "  if output_predicted_label:\n",
        "      out_df['predicted'] = np.argmax(out_df, axis=1)\n",
        "  \n",
        "  if label_values is not None:\n",
        "      out_df.columns = label_values\n",
        "  \n",
        "  if test_case_ids is not None:\n",
        "      out_df.insert(0, 'id', test_case_ids)\n",
        "\n",
        "  return out_df\n",
        "  \n",
        "# compute evaluation metrics\n",
        "def evaluate_model(actual: List, predicted: List, label_values = None, **kwargs):\n",
        "  \"\"\"Calculate evaluation metrics on test labels\n",
        "  \n",
        "  Args:\n",
        "    actual: list of actual labels\n",
        "    predicted: list of predicted labels\n",
        "    label_values: A *unique ordered* list of labels (optional)\n",
        "    kwargs: Additional arguments to pass to sklearn.metrics.classification_report\n",
        "  \"\"\"\n",
        "\n",
        "  if label_values is not None:\n",
        "      kwargs.update({'target_names': label_values})\n",
        "  else:\n",
        "      kwargs.update({'target_names': list(dict.fromkeys(actual))})\n",
        "      \n",
        "  return classification_report(y_true = actual, y_pred = predicted, **kwargs)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdULdNEfUYb1"
      },
      "source": [
        "### Selecting Model and Hyper-Parameters\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8tlBiCW5mBy"
      },
      "outputs": [],
      "source": [
        "#@title Define model to train\n",
        "transformer_model = \"deberta\" #@param [\"deberta\", \"albert\", \"bert\", \"bart\", \"distilbert\",\"distilroberta\", \"electra\", \"roberta\", \"xlnet\", \"xlmroberta\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GAQl22KulEr"
      },
      "outputs": [],
      "source": [
        "#@title Define training hyper-parameters\n",
        "\n",
        "# length to pad items to (we choose a small number because personality items are generally short)\n",
        "SEQ_LEN = 32\n",
        "\n",
        "# first we can initialized the ClassificationArguments object\n",
        "training_args = TrainingArguments(\n",
        "   num_train_epochs = 10,\n",
        "   learning_rate = 2e-5,\n",
        "   warmup_ratio = 0.10,\n",
        "   weight_decay = 0.01,\n",
        "   per_device_train_batch_size = 16,\n",
        "   seed = 42,\n",
        "   load_best_model_at_end=True,\n",
        "   evaluation_strategy=\"steps\", \n",
        "   output_dir = f\"{transformer_model}/outputs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU5mojBFURyy"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Fine-tuning A Transformer Model\n",
        "\n",
        "\n",
        "---\n",
        "This example demonstrates the fine-tuning process for the purpose of classifying personality items into their respective dimensions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoOpPwcYvTvc"
      },
      "source": [
        "### Importing and Formatting Training Data\n",
        "\n",
        "\n",
        "Given that the training data comprises a compilation of developed personality items, we have made this training data accessible online. This is intended to assist researchers in leveraging this model for similar text selection objectives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYmz5jdG_LWS"
      },
      "outputs": [],
      "source": [
        "# Assign the online data repository to a url so it doesn't have to be repeated later\n",
        "repository_data_url = 'https://anonymous.4open.science/api/repo/transforming-personality-scales/file/data/text-classification/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD0E9EpLr3-V"
      },
      "outputs": [],
      "source": [
        "#@title Importing training dataset\n",
        "# the import_data function will return a list of sentences, a list of labels, and the original dataset\n",
        "train_text, train_labels, raw_training_data = import_data(repository_data_url + 'train-data.csv', \"text\", \"label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob7mKIM_8Dpz"
      },
      "source": [
        "To properly import the training data we must specify the file path, column name containing our items, and column name containing our labels. Then, the `import_data()` returns three objects:\n",
        "\n",
        "- a list (vector) of items\n",
        "- a list (vector) of labels\n",
        "- a copy of our training data\n",
        "\n",
        "The code above assigns these to objects names `train_text`, `train_labels` and `raw_data` respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm6IMLaY-lu-"
      },
      "source": [
        "### Training the Model\n",
        "\n",
        "---\n",
        "\n",
        "Our fine-tune function only requires that we define the `Transformer model` we would like to use, as well as `input a vector of text` (i.e., personality items in this example), the `trait labels`, and the `training arguments` (which we defined in the **Selecting Model and Hyper-Parameters** section of this tutorial). There are optional arguments, such as time-stamping the output directory, which would be a good ideal if training mulitple models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_tmG_6v-3oC"
      },
      "outputs": [],
      "source": [
        "# tune the model using the labeled personality items\n",
        "fine_tuned_model, tokenizer = fine_tune(transformer_model, train_text, train_labels, training_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldtRKgWMtGIP"
      },
      "source": [
        "### Testing the Model\n",
        "\n",
        "---\n",
        "\n",
        "Since we've fined tuned the model we can use the `.predict()` method to predict the labels of new text---for example---personality items, survey responses, and even performance evaluations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC4VyJrCsxQl"
      },
      "source": [
        "#### Import the test data\n",
        "First, we must import the test data (`test-data.csv`), making sure we only specify the `path (url)` and `text_col` in the `import_data()` function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Importing testing dataset\n",
        "# \"text\" refers to the column name that contain splited sentences\n",
        "# Change the test data to your own data if you want to use the fine-tuned personality classification model to generate probability scores as a relevance index\n",
        "test_text, test_labels, raw_testing_data = import_data(repository_data_url + 'test-data.csv', \"text\", \"label\")"
      ],
      "metadata": {
        "id": "eU8PPZy-9xf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4Roz1kCifzq"
      },
      "outputs": [],
      "source": [
        "# tokenizing the test data before prediction\n",
        "test_encodings = tokenizer(test_text, truncation=True, padding=True)\n",
        "test_dataset = TextClassificationDataset(test_encodings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrMpanHluUfx"
      },
      "source": [
        "#### Predict labels of the test items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9FTP0LlVsHol"
      },
      "outputs": [],
      "source": [
        "# predict the test set and return single label predictions and the raw logits\n",
        "predictions, _, _ = fine_tuned_model.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOooERhwBF5h"
      },
      "source": [
        "By default the `format_output_data` function will return multi-class probabilities and the most likely label, which is appended as a column named *'predicted'*. These options can be modified by setting the arguments `output_probabilities` and `output_predicted_label` to `False`. For example:\n",
        "\n",
        "```\n",
        "# output predicted label and logit values\n",
        "out_test_df = format_output_data(predictions, output_probabilities = False)\n",
        "\n",
        "# output probabilities but no predicted label\n",
        "out_test_df = format_output_data(predictions, output_predicted_label = False)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqiII1y0uahz"
      },
      "outputs": [],
      "source": [
        "# we can format the output and save it\n",
        "out_test_df = format_output_data(predictions, output_predicted_label = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdmSmmGAvhDr"
      },
      "outputs": [],
      "source": [
        "# save results if you are running the model to get probability scores\n",
        "# out_test_df.to_csv('/content/drive/MyDrive/Text Selection Paper Codes/classification_probabilities.csv')\n",
        "# Based on this output file. We can further select the most relevant N sentences from original dataset."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}